{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Convoluted Neural Networks to forecast Crop Yield from NDVI scaled Satellite Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import (Input, Conv2D, MaxPooling2D, AveragePooling2D, UpSampling2D, Dropout,\n",
    "                          Conv2DTranspose, concatenate)\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = 'C:\\\\Users\\\\anupriya\\\\Desktop\\\\ndvi_img\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = []\n",
    "for root, dirs, files in os.walk(IMG_PATH):\n",
    "    for filename in files:\n",
    "        img_name.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "county = ['kings', 'fresno', 'sanjoaquin', 'solano', 'stanislaus', 'yolo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_load = []\n",
    "for county in county:\n",
    "    for root, dirs, files in os.walk(IMG_PATH+county+'/'):\n",
    "        for filename in files:\n",
    "            img_load.append(plt.imread(root+filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arr in img_load:\n",
    "    print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_h = []\n",
    "img_w = []\n",
    "\n",
    "for arr in img_load:\n",
    "    img_h.append(arr.shape[0])\n",
    "    img_w.append(arr.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 316\n",
      "102 357\n"
     ]
    }
   ],
   "source": [
    "print(min(img_h), max(img_h))\n",
    "print(min(img_w), max(img_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESIZE IMAGES\n",
    "\n",
    "#img = cv2.imread('YOUR_PATH_TO_IMG')\n",
    "new_img = []\n",
    "\n",
    "for img_arr in img_load:\n",
    "    height, width = img_arr.shape[:2]\n",
    "    max_height = 316\n",
    "    max_width = 357\n",
    "\n",
    "    if width < max_width or height < max_height:\n",
    "        new_img.append(cv2.resize(img_arr, (357,316)))\n",
    "    \n",
    "    # only shrink if img is bigger than required\n",
    "     if max_height < height or max_width < width:\n",
    "        # get scaling factor\n",
    "        scaling_factor = max_height / float(height)\n",
    "        if max_width/float(width) < scaling_factor:\n",
    "             scaling_factor = max_width / float(width)\n",
    "         # resize image\n",
    "         new_img.append(cv2.resize(img_arr, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA))\n",
    "\n",
    "    cv2.imshow(\"Shrinked image\", img)\n",
    "    key = cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arr = []\n",
    "\n",
    "for arr in img_load:\n",
    "    \n",
    "    target_h = int((arr.shape[0]-300)/2)\n",
    "    target_w = int((arr.shape[1]-250)/2)\n",
    "    new_arr.append(arr[target_h:300+target_h,target_w:250+target_w,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = np.array(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 316, 357, 4)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arr = np.array(new_arr)\n",
    "new_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load yield data\n",
    "yield_df = pd.read_excel(\"USDA_yield_CAandOH.xlsx\")\n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Period</th>\n",
       "      <th>Week Ending</th>\n",
       "      <th>Geo Level</th>\n",
       "      <th>State</th>\n",
       "      <th>State ANSI</th>\n",
       "      <th>Ag District</th>\n",
       "      <th>Ag District Code</th>\n",
       "      <th>County</th>\n",
       "      <th>County ANSI</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Region</th>\n",
       "      <th>watershed_code</th>\n",
       "      <th>Watershed</th>\n",
       "      <th>Commodity</th>\n",
       "      <th>Data Item</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Domain Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>CV (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SURVEY</td>\n",
       "      <td>1973</td>\n",
       "      <td>YEAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COUNTY</td>\n",
       "      <td>OHIO</td>\n",
       "      <td>39</td>\n",
       "      <td>NORTHWEST</td>\n",
       "      <td>10</td>\n",
       "      <td>OTHER (COMBINED) COUNTIES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TOMATOES</td>\n",
       "      <td>TOMATOES, IN THE OPEN, PROCESSING - YIELD, MEA...</td>\n",
       "      <td>TOTAL</td>\n",
       "      <td>NOT SPECIFIED</td>\n",
       "      <td>1.60</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SURVEY</td>\n",
       "      <td>1981</td>\n",
       "      <td>YEAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COUNTY</td>\n",
       "      <td>OHIO</td>\n",
       "      <td>39</td>\n",
       "      <td>WEST CENTRAL</td>\n",
       "      <td>40</td>\n",
       "      <td>OTHER (COMBINED) COUNTIES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TOMATOES</td>\n",
       "      <td>TOMATOES, IN THE OPEN, PROCESSING - YIELD, MEA...</td>\n",
       "      <td>TOTAL</td>\n",
       "      <td>NOT SPECIFIED</td>\n",
       "      <td>10.70</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SURVEY</td>\n",
       "      <td>2002</td>\n",
       "      <td>YEAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COUNTY</td>\n",
       "      <td>OHIO</td>\n",
       "      <td>39</td>\n",
       "      <td>WEST CENTRAL</td>\n",
       "      <td>40</td>\n",
       "      <td>OTHER (COMBINED) COUNTIES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TOMATOES</td>\n",
       "      <td>TOMATOES, IN THE OPEN, PROCESSING - YIELD, MEA...</td>\n",
       "      <td>TOTAL</td>\n",
       "      <td>NOT SPECIFIED</td>\n",
       "      <td>12.14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SURVEY</td>\n",
       "      <td>1974</td>\n",
       "      <td>YEAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COUNTY</td>\n",
       "      <td>OHIO</td>\n",
       "      <td>39</td>\n",
       "      <td>WEST CENTRAL</td>\n",
       "      <td>40</td>\n",
       "      <td>OTHER (COMBINED) COUNTIES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TOMATOES</td>\n",
       "      <td>TOMATOES, IN THE OPEN, PROCESSING - YIELD, MEA...</td>\n",
       "      <td>TOTAL</td>\n",
       "      <td>NOT SPECIFIED</td>\n",
       "      <td>13.39</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SURVEY</td>\n",
       "      <td>1975</td>\n",
       "      <td>YEAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COUNTY</td>\n",
       "      <td>OHIO</td>\n",
       "      <td>39</td>\n",
       "      <td>WEST CENTRAL</td>\n",
       "      <td>40</td>\n",
       "      <td>OTHER (COMBINED) COUNTIES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TOMATOES</td>\n",
       "      <td>TOMATOES, IN THE OPEN, PROCESSING - YIELD, MEA...</td>\n",
       "      <td>TOTAL</td>\n",
       "      <td>NOT SPECIFIED</td>\n",
       "      <td>13.41</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Year Period  Week Ending Geo Level State  \\\n",
       "0                      SURVEY  1973   YEAR          NaN    COUNTY  OHIO   \n",
       "1                      SURVEY  1981   YEAR          NaN    COUNTY  OHIO   \n",
       "2                      SURVEY  2002   YEAR          NaN    COUNTY  OHIO   \n",
       "3                      SURVEY  1974   YEAR          NaN    COUNTY  OHIO   \n",
       "4                      SURVEY  1975   YEAR          NaN    COUNTY  OHIO   \n",
       "\n",
       "   State ANSI   Ag District  Ag District Code                     County  \\\n",
       "0          39     NORTHWEST                10  OTHER (COMBINED) COUNTIES   \n",
       "1          39  WEST CENTRAL                40  OTHER (COMBINED) COUNTIES   \n",
       "2          39  WEST CENTRAL                40  OTHER (COMBINED) COUNTIES   \n",
       "3          39  WEST CENTRAL                40  OTHER (COMBINED) COUNTIES   \n",
       "4          39  WEST CENTRAL                40  OTHER (COMBINED) COUNTIES   \n",
       "\n",
       "   County ANSI  Zip Code  Region  watershed_code  Watershed Commodity  \\\n",
       "0          NaN       NaN     NaN               0        NaN  TOMATOES   \n",
       "1          NaN       NaN     NaN               0        NaN  TOMATOES   \n",
       "2          NaN       NaN     NaN               0        NaN  TOMATOES   \n",
       "3          NaN       NaN     NaN               0        NaN  TOMATOES   \n",
       "4          NaN       NaN     NaN               0        NaN  TOMATOES   \n",
       "\n",
       "                                           Data Item Domain Domain Category  \\\n",
       "0  TOMATOES, IN THE OPEN, PROCESSING - YIELD, MEA...  TOTAL   NOT SPECIFIED   \n",
       "1  TOMATOES, IN THE OPEN, PROCESSING - YIELD, MEA...  TOTAL   NOT SPECIFIED   \n",
       "2  TOMATOES, IN THE OPEN, PROCESSING - YIELD, MEA...  TOTAL   NOT SPECIFIED   \n",
       "3  TOMATOES, IN THE OPEN, PROCESSING - YIELD, MEA...  TOTAL   NOT SPECIFIED   \n",
       "4  TOMATOES, IN THE OPEN, PROCESSING - YIELD, MEA...  TOTAL   NOT SPECIFIED   \n",
       "\n",
       "   Value  CV (%)  \n",
       "0   1.60     NaN  \n",
       "1  10.70     NaN  \n",
       "2  12.14     NaN  \n",
       "3  13.39     NaN  \n",
       "4  13.41     NaN  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yield_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_sub = yield_df[['Year', 'State', 'County', 'Value']]\n",
    "yield_sub = yield_sub[yield_sub['Year'] >= 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the df into CA and OHIO\n",
    "ca_yield = yield_sub[yield_sub['State'] == 'CALIFORNIA']\n",
    "oh_yield = yield_sub[yield_sub['State'] == 'OHIO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = ca_yield.groupby(['County','Year'])[['Value']].sum()\n",
    "ca.to_csv('ca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_img\n",
    "y = df.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.expand_dims(X_test, 0)\n",
    "# a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = new_arr[-1]\n",
    "y_test = yd.iloc[-1,1]\n",
    "X_test = np.expand_dims(X_test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(n_channels=4, growth_factor=2, filter_size=(3,3)):\n",
    "    # Creating network model using functional API:\n",
    "    \n",
    "    # first\n",
    "    n_filters = n_channels*growth_factor\n",
    "    \n",
    "    inputs = Input((316, 357, n_channels))\n",
    "    conv1 = Conv2D(n_filters, filter_size, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(n_filters, filter_size, activation='relu', padding='same')(conv1)\n",
    "    pool1 = AveragePooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    # second\n",
    "    n_filters *= growth_factor  # increase number of filters when going down the U-Net    \n",
    "    conv2 = Conv2D(n_filters, filter_size, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(n_filters, filter_size, activation='relu', padding='same')(conv2)\n",
    "    pool2 = AveragePooling2D(pool_size=(2, 2))(conv2)\n",
    " \n",
    "    # third\n",
    "    n_filters *= growth_factor  # increase number of filters when going down the U-Net    \n",
    "    conv3 = Conv2D(n_filters, filter_size, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(n_filters, filter_size, activation='relu', padding='same')(conv3)\n",
    "    pool3 = AveragePooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    # fourth\n",
    "    n_filters *= growth_factor  # increase number of filters when going down the U-Net    \n",
    "    conv4 = Conv2D(n_filters, filter_size, activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(n_filters, filter_size, activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    dropout = Dropout(0.3)\n",
    "\n",
    "    # output\n",
    "    fc1 = Flatten()(pool4)\n",
    "    fc2 = Dense(4588, activation='linear')(fc1)\n",
    "    output = Dense(1, kernel_initializer='normal',activation='linear')(fc1)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    optimizer = Adam()\n",
    "    # Compiling model with ADAM optimizer and logloss (aka binary crossentropy) as loss function\n",
    "    model.compile(loss=root_mean_squared_error, optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 316, 357, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 316, 357, 8)       296       \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 316, 357, 8)       584       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_10 (Averag (None, 158, 178, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 158, 178, 16)      1168      \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 158, 178, 16)      2320      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_11 (Averag (None, 79, 89, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 79, 89, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 79, 89, 32)        9248      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_12 (Averag (None, 39, 44, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 39, 44, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 39, 44, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 19, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 26752)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 26753     \n",
      "=================================================================\n",
      "Total params: 100,433\n",
      "Trainable params: 100,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = cnn_model(n_channels=4)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47 samples, validate on 6 samples\n",
      "Epoch 1/350\n",
      "47/47 [==============================] - 6s 133ms/step - loss: 43.4737 - val_loss: 44.8890\n",
      "Epoch 2/350\n",
      "47/47 [==============================] - 6s 122ms/step - loss: 42.1869 - val_loss: 40.2367\n",
      "Epoch 3/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 35.7834 - val_loss: 20.1272\n",
      "Epoch 4/350\n",
      "47/47 [==============================] - 6s 123ms/step - loss: 14.6553 - val_loss: 9.2753\n",
      "Epoch 5/350\n",
      "47/47 [==============================] - 6s 129ms/step - loss: 9.3142 - val_loss: 12.1292\n",
      "Epoch 6/350\n",
      "47/47 [==============================] - 6s 128ms/step - loss: 10.1029 - val_loss: 8.4422\n",
      "Epoch 7/350\n",
      "47/47 [==============================] - 6s 126ms/step - loss: 5.7238 - val_loss: 5.8574\n",
      "Epoch 8/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 7.5976 - val_loss: 3.8408\n",
      "Epoch 9/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 4.0774 - val_loss: 6.4160\n",
      "Epoch 10/350\n",
      "47/47 [==============================] - 6s 117ms/step - loss: 4.5589 - val_loss: 1.6904\n",
      "Epoch 11/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 4.7993 - val_loss: 2.4571\n",
      "Epoch 12/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 4.2548 - val_loss: 4.5612\n",
      "Epoch 13/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 4.2288 - val_loss: 2.2063\n",
      "Epoch 14/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.9611 - val_loss: 2.4885\n",
      "Epoch 15/350\n",
      "47/47 [==============================] - 6s 117ms/step - loss: 3.7906 - val_loss: 2.1999\n",
      "Epoch 16/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 3.8175 - val_loss: 3.6615\n",
      "Epoch 17/350\n",
      "47/47 [==============================] - 6s 122ms/step - loss: 3.8283 - val_loss: 3.0014\n",
      "Epoch 18/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.6890 - val_loss: 1.9372\n",
      "Epoch 19/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 4.2219 - val_loss: 4.4233\n",
      "Epoch 20/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.9505 - val_loss: 3.8532\n",
      "Epoch 21/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.8983 - val_loss: 2.1804\n",
      "Epoch 22/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.8623 - val_loss: 3.1714\n",
      "Epoch 23/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.6727 - val_loss: 4.2691\n",
      "Epoch 24/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 3.7794 - val_loss: 2.7756\n",
      "Epoch 25/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.6506 - val_loss: 2.2920\n",
      "Epoch 26/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.7166 - val_loss: 5.6527\n",
      "Epoch 27/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 4.2222 - val_loss: 3.8468\n",
      "Epoch 28/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 3.7843 - val_loss: 2.3181\n",
      "Epoch 29/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.8664 - val_loss: 5.4865\n",
      "Epoch 30/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.7619 - val_loss: 1.6946\n",
      "Epoch 31/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 4.4123 - val_loss: 6.2481\n",
      "Epoch 32/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 4.4033 - val_loss: 3.0630\n",
      "Epoch 33/350\n",
      "47/47 [==============================] - 6s 122ms/step - loss: 4.0940 - val_loss: 2.5139\n",
      "Epoch 34/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 3.4698 - val_loss: 6.1820\n",
      "Epoch 35/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 4.0575 - val_loss: 2.0231\n",
      "Epoch 36/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.7652 - val_loss: 6.3087\n",
      "Epoch 37/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 4.5845 - val_loss: 4.8690\n",
      "Epoch 38/350\n",
      "47/47 [==============================] - 5s 117ms/step - loss: 3.5093 - val_loss: 1.6997\n",
      "Epoch 39/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 4.4815 - val_loss: 5.7617\n",
      "Epoch 40/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 3.7877 - val_loss: 2.1310\n",
      "Epoch 41/350\n",
      "47/47 [==============================] - 5s 117ms/step - loss: 3.7134 - val_loss: 4.4419\n",
      "Epoch 42/350\n",
      "47/47 [==============================] - 6s 122ms/step - loss: 3.4487 - val_loss: 2.7156\n",
      "Epoch 43/350\n",
      "47/47 [==============================] - 5s 116ms/step - loss: 3.8127 - val_loss: 3.4860\n",
      "Epoch 44/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 3.4801 - val_loss: 5.8775\n",
      "Epoch 45/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.9819 - val_loss: 2.9648\n",
      "Epoch 46/350\n",
      "47/47 [==============================] - 6s 122ms/step - loss: 3.4041 - val_loss: 2.5687\n",
      "Epoch 47/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.6632 - val_loss: 4.9257\n",
      "Epoch 48/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 3.7814 - val_loss: 3.8168\n",
      "Epoch 49/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.6008 - val_loss: 3.1552\n",
      "Epoch 50/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.3294 - val_loss: 6.0264\n",
      "Epoch 51/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.7350 - val_loss: 1.7113\n",
      "Epoch 52/350\n",
      "47/47 [==============================] - 6s 123ms/step - loss: 4.5879 - val_loss: 4.2072\n",
      "Epoch 53/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 3.4896 - val_loss: 3.2366\n",
      "Epoch 54/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 4.0807 - val_loss: 2.6016\n",
      "Epoch 55/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 3.5749 - val_loss: 6.1663\n",
      "Epoch 56/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.8122 - val_loss: 1.7470\n",
      "Epoch 57/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 4.8462 - val_loss: 7.7797\n",
      "Epoch 58/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 4.9559 - val_loss: 5.3351\n",
      "Epoch 59/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.9794 - val_loss: 2.2064\n",
      "Epoch 60/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.5977 - val_loss: 8.4386\n",
      "Epoch 61/350\n",
      "47/47 [==============================] - 5s 117ms/step - loss: 5.0407 - val_loss: 2.5095\n",
      "Epoch 62/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.5332 - val_loss: 3.3262\n",
      "Epoch 63/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 3.1259 - val_loss: 6.5676\n",
      "Epoch 64/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.9959 - val_loss: 2.2885\n",
      "Epoch 65/350\n",
      "47/47 [==============================] - 6s 122ms/step - loss: 3.3944 - val_loss: 2.2787\n",
      "Epoch 66/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 3.2081 - val_loss: 5.8141\n",
      "Epoch 67/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 3.6830 - val_loss: 2.5604\n",
      "Epoch 68/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.3461 - val_loss: 4.5096\n",
      "Epoch 69/350\n",
      "47/47 [==============================] - 6s 124ms/step - loss: 3.5886 - val_loss: 4.6923\n",
      "Epoch 70/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.9547 - val_loss: 4.3873\n",
      "Epoch 71/350\n",
      "47/47 [==============================] - 6s 117ms/step - loss: 3.8795 - val_loss: 5.0926\n",
      "Epoch 72/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.6060 - val_loss: 2.1342\n",
      "Epoch 73/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.7258 - val_loss: 5.5077\n",
      "Epoch 74/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.4805 - val_loss: 2.3142\n",
      "Epoch 75/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.2786 - val_loss: 5.4794\n",
      "Epoch 76/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.4474 - val_loss: 3.6898\n",
      "Epoch 77/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 3.0414 - val_loss: 2.3592\n",
      "Epoch 78/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.3796 - val_loss: 5.6181\n",
      "Epoch 79/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 3.4953 - val_loss: 4.0386\n",
      "Epoch 80/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 3.1139 - val_loss: 4.2437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.1301 - val_loss: 3.5141\n",
      "Epoch 82/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 3.2697 - val_loss: 6.1689\n",
      "Epoch 83/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.7879 - val_loss: 2.7259\n",
      "Epoch 84/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 4.1015 - val_loss: 5.7057\n",
      "Epoch 85/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.8306 - val_loss: 7.2012\n",
      "Epoch 86/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 4.0281 - val_loss: 3.2519\n",
      "Epoch 87/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.0676 - val_loss: 4.7547\n",
      "Epoch 88/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 3.1177 - val_loss: 3.0588\n",
      "Epoch 89/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.1899 - val_loss: 5.3773\n",
      "Epoch 90/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.3911 - val_loss: 2.8466\n",
      "Epoch 91/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.0789 - val_loss: 4.8320\n",
      "Epoch 92/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 3.1189 - val_loss: 3.1000\n",
      "Epoch 93/350\n",
      "47/47 [==============================] - 6s 122ms/step - loss: 3.0963 - val_loss: 5.0136\n",
      "Epoch 94/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.3032 - val_loss: 2.0258\n",
      "Epoch 95/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.9757 - val_loss: 8.1392\n",
      "Epoch 96/350\n",
      "47/47 [==============================] - 6s 122ms/step - loss: 5.0540 - val_loss: 7.2237\n",
      "Epoch 97/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 4.4051 - val_loss: 1.7124\n",
      "Epoch 98/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 4.9293 - val_loss: 7.9442\n",
      "Epoch 99/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 4.4372 - val_loss: 2.2458\n",
      "Epoch 100/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.7041 - val_loss: 4.4173\n",
      "Epoch 101/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 3.1654 - val_loss: 6.4849\n",
      "Epoch 102/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.5332 - val_loss: 2.0175\n",
      "Epoch 103/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 3.7763 - val_loss: 4.5086\n",
      "Epoch 104/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.2189 - val_loss: 4.6061\n",
      "Epoch 105/350\n",
      "47/47 [==============================] - 6s 122ms/step - loss: 3.0343 - val_loss: 4.0221\n",
      "Epoch 106/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 3.0436 - val_loss: 5.0247\n",
      "Epoch 107/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 3.1743 - val_loss: 3.6556\n",
      "Epoch 108/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 3.0220 - val_loss: 4.9349\n",
      "Epoch 109/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.0556 - val_loss: 4.7656\n",
      "Epoch 110/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.0450 - val_loss: 3.5298\n",
      "Epoch 111/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.1761 - val_loss: 5.5268\n",
      "Epoch 112/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 3.1437 - val_loss: 4.2496\n",
      "Epoch 113/350\n",
      "47/47 [==============================] - 6s 117ms/step - loss: 3.1825 - val_loss: 3.8543\n",
      "Epoch 114/350\n",
      "47/47 [==============================] - 6s 127ms/step - loss: 3.3278 - val_loss: 6.0261\n",
      "Epoch 115/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.3075 - val_loss: 6.6535\n",
      "Epoch 116/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.1866 - val_loss: 2.0546\n",
      "Epoch 117/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.7968 - val_loss: 7.4450\n",
      "Epoch 118/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 4.1600 - val_loss: 4.3387\n",
      "Epoch 119/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 3.3683 - val_loss: 2.3111\n",
      "Epoch 120/350\n",
      "47/47 [==============================] - 6s 117ms/step - loss: 3.2176 - val_loss: 7.2760\n",
      "Epoch 121/350\n",
      "47/47 [==============================] - 5s 117ms/step - loss: 3.7873 - val_loss: 2.0447\n",
      "Epoch 122/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 4.1108 - val_loss: 7.2114\n",
      "Epoch 123/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 4.6325 - val_loss: 8.2781\n",
      "Epoch 124/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 4.6714 - val_loss: 1.7192\n",
      "Epoch 125/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 4.1609 - val_loss: 8.9193\n",
      "Epoch 126/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 5.5442 - val_loss: 6.6806\n",
      "Epoch 127/350\n",
      "47/47 [==============================] - 6s 122ms/step - loss: 4.0841 - val_loss: 1.7647\n",
      "Epoch 128/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 4.8029 - val_loss: 8.4217\n",
      "Epoch 129/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 4.8340 - val_loss: 4.5231\n",
      "Epoch 130/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.2690 - val_loss: 2.1651\n",
      "Epoch 131/350\n",
      "47/47 [==============================] - 6s 122ms/step - loss: 3.9383 - val_loss: 6.8798\n",
      "Epoch 132/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.5224 - val_loss: 2.1395\n",
      "Epoch 133/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 3.7829 - val_loss: 5.6885\n",
      "Epoch 134/350\n",
      "47/47 [==============================] - 6s 122ms/step - loss: 3.5211 - val_loss: 5.3560\n",
      "Epoch 135/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 2.6013 - val_loss: 2.0452\n",
      "Epoch 136/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 3.5744 - val_loss: 9.8248\n",
      "Epoch 137/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 5.7660 - val_loss: 5.7263\n",
      "Epoch 138/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 3.7391 - val_loss: 2.4437\n",
      "Epoch 139/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.5916 - val_loss: 10.2542\n",
      "Epoch 140/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 5.7316 - val_loss: 2.3025\n",
      "Epoch 141/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 4.2593 - val_loss: 2.6065\n",
      "Epoch 142/350\n",
      "47/47 [==============================] - 5s 117ms/step - loss: 3.6381 - val_loss: 9.0915\n",
      "Epoch 143/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 4.8731 - val_loss: 2.2061\n",
      "Epoch 144/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 4.0069 - val_loss: 4.6485\n",
      "Epoch 145/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 4.0201 - val_loss: 7.0648\n",
      "Epoch 146/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 3.6307 - val_loss: 1.7549\n",
      "Epoch 147/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 4.6517 - val_loss: 8.6637\n",
      "Epoch 148/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 5.4874 - val_loss: 7.8187\n",
      "Epoch 149/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 4.0424 - val_loss: 1.7630\n",
      "Epoch 150/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 4.9148 - val_loss: 7.4578\n",
      "Epoch 151/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 4.2649 - val_loss: 6.0684\n",
      "Epoch 152/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.1071 - val_loss: 2.3328\n",
      "Epoch 153/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.6776 - val_loss: 8.6405\n",
      "Epoch 154/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 4.2835 - val_loss: 2.6135\n",
      "Epoch 155/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.4669 - val_loss: 4.9121\n",
      "Epoch 156/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 2.8938 - val_loss: 6.1019\n",
      "Epoch 157/350\n",
      "47/47 [==============================] - 6s 122ms/step - loss: 2.8847 - val_loss: 3.3612\n",
      "Epoch 158/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.0770 - val_loss: 5.2592\n",
      "Epoch 159/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 2.7149 - val_loss: 3.5936\n",
      "Epoch 160/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 2.9343 - val_loss: 6.8662\n",
      "Epoch 161/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 2.8079 - val_loss: 5.1318\n",
      "Epoch 162/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 2.5975 - val_loss: 5.2797\n",
      "Epoch 163/350\n",
      "47/47 [==============================] - 5s 117ms/step - loss: 2.6892 - val_loss: 7.4466\n",
      "Epoch 164/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 2.5433 - val_loss: 3.2275\n",
      "Epoch 165/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 3.0629 - val_loss: 6.8971\n",
      "Epoch 166/350\n",
      "47/47 [==============================] - 6s 117ms/step - loss: 3.0011 - val_loss: 8.4451\n",
      "Epoch 167/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 2.9925 - val_loss: 5.9713\n",
      "Epoch 168/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 2.4676 - val_loss: 5.8102\n",
      "Epoch 169/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 2.6163 - val_loss: 10.0470\n",
      "Epoch 170/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 3.5803 - val_loss: 3.1238\n",
      "Epoch 171/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 4.4697 - val_loss: 9.7309\n",
      "Epoch 172/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 3.4560 - val_loss: 4.8686\n",
      "Epoch 173/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 2.8530 - val_loss: 8.8945\n",
      "Epoch 174/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 2.0383 - val_loss: 5.1154\n",
      "Epoch 175/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 2.5410 - val_loss: 11.5401\n",
      "Epoch 176/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.4706 - val_loss: 2.7263\n",
      "Epoch 177/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 5.4067 - val_loss: 11.0859\n",
      "Epoch 178/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 4.4999 - val_loss: 7.8793\n",
      "Epoch 179/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 3.6519 - val_loss: 2.8283\n",
      "Epoch 180/350\n",
      "47/47 [==============================] - 6s 117ms/step - loss: 4.1672 - val_loss: 9.0284\n",
      "Epoch 181/350\n",
      "47/47 [==============================] - 6s 122ms/step - loss: 2.4538 - val_loss: 2.5638\n",
      "Epoch 182/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 4.0795 - val_loss: 11.6411\n",
      "Epoch 183/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 5.9195 - val_loss: 9.9789\n",
      "Epoch 184/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.9614 - val_loss: 2.4187\n",
      "Epoch 185/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 4.4177 - val_loss: 9.3260\n",
      "Epoch 186/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.6122 - val_loss: 4.4880\n",
      "Epoch 187/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 3.4626 - val_loss: 4.4701\n",
      "Epoch 188/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 2.8149 - val_loss: 8.6319\n",
      "Epoch 189/350\n",
      "47/47 [==============================] - 6s 117ms/step - loss: 2.6944 - val_loss: 6.4640\n",
      "Epoch 190/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 2.0528 - val_loss: 6.8002\n",
      "Epoch 191/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 1.8276 - val_loss: 8.5005\n",
      "Epoch 192/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 1.7725 - val_loss: 5.9573\n",
      "Epoch 193/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 2.3675 - val_loss: 11.0324\n",
      "Epoch 194/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 2.5731 - val_loss: 5.3846\n",
      "Epoch 195/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 2.7816 - val_loss: 9.8978\n",
      "Epoch 196/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 2.6270 - val_loss: 8.3198\n",
      "Epoch 197/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 1.7692 - val_loss: 7.2418\n",
      "Epoch 198/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 1.9210 - val_loss: 11.5063\n",
      "Epoch 199/350\n",
      "47/47 [==============================] - 6s 122ms/step - loss: 2.8340 - val_loss: 4.3483\n",
      "Epoch 200/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.4946 - val_loss: 12.8706\n",
      "Epoch 201/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 5.6783 - val_loss: 7.4567\n",
      "Epoch 202/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 3.3905 - val_loss: 4.0491\n",
      "Epoch 203/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.8067 - val_loss: 12.9591\n",
      "Epoch 204/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 4.1543 - val_loss: 3.4026\n",
      "Epoch 205/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 4.1560 - val_loss: 8.8919\n",
      "Epoch 206/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.1245 - val_loss: 6.5871\n",
      "Epoch 207/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 2.3808 - val_loss: 5.6513\n",
      "Epoch 208/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 1.8936 - val_loss: 10.0666\n",
      "Epoch 209/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 2.3259 - val_loss: 2.7133\n",
      "Epoch 210/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 5.1539 - val_loss: 8.9612\n",
      "Epoch 211/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 2.1449 - val_loss: 6.6747\n",
      "Epoch 212/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 1.5105 - val_loss: 6.8656\n",
      "Epoch 213/350\n",
      "47/47 [==============================] - 5s 116ms/step - loss: 1.7016 - val_loss: 6.2276\n",
      "Epoch 214/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 1.4033 - val_loss: 10.1085\n",
      "Epoch 215/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 2.5507 - val_loss: 4.7309\n",
      "Epoch 216/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 2.7473 - val_loss: 10.8990\n",
      "Epoch 217/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.3827 - val_loss: 4.6717\n",
      "Epoch 218/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 2.6888 - val_loss: 10.1898\n",
      "Epoch 219/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 3.2164 - val_loss: 5.5624\n",
      "Epoch 220/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 1.5633 - val_loss: 8.8564\n",
      "Epoch 221/350\n",
      "47/47 [==============================] - 6s 124ms/step - loss: 2.0178 - val_loss: 3.2291\n",
      "Epoch 222/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.3460 - val_loss: 10.9777\n",
      "Epoch 223/350\n",
      "47/47 [==============================] - 5s 116ms/step - loss: 4.8448 - val_loss: 9.0203\n",
      "Epoch 224/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 3.6450 - val_loss: 2.3373\n",
      "Epoch 225/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 5.5563 - val_loss: 12.8960\n",
      "Epoch 226/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 6.3202 - val_loss: 12.8749\n",
      "Epoch 227/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 4.8674 - val_loss: 2.9778\n",
      "Epoch 228/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.2270 - val_loss: 9.6303\n",
      "Epoch 229/350\n",
      "47/47 [==============================] - 6s 117ms/step - loss: 3.0291 - val_loss: 4.7304\n",
      "Epoch 230/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 2.4096 - val_loss: 6.9358\n",
      "Epoch 231/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 1.9127 - val_loss: 6.6831\n",
      "Epoch 232/350\n",
      "47/47 [==============================] - 5s 117ms/step - loss: 1.6671 - val_loss: 8.0419\n",
      "Epoch 233/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 1.5628 - val_loss: 6.7231\n",
      "Epoch 234/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 1.7603 - val_loss: 11.2256\n",
      "Epoch 235/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 2.5360 - val_loss: 6.7986\n",
      "Epoch 236/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 2.1054 - val_loss: 11.6678\n",
      "Epoch 237/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 2.9665 - val_loss: 6.7288\n",
      "Epoch 238/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 1.9022 - val_loss: 11.4919\n",
      "Epoch 239/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 6s 117ms/step - loss: 3.9464 - val_loss: 7.8395\n",
      "Epoch 240/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 1.7747 - val_loss: 6.1745\n",
      "Epoch 241/350\n",
      "47/47 [==============================] - 6s 117ms/step - loss: 2.7155 - val_loss: 12.7627\n",
      "Epoch 242/350\n",
      "47/47 [==============================] - 6s 117ms/step - loss: 4.2509 - val_loss: 3.2197\n",
      "Epoch 243/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 6.0871 - val_loss: 5.5752\n",
      "Epoch 244/350\n",
      "47/47 [==============================] - 5s 117ms/step - loss: 3.5256 - val_loss: 15.8145\n",
      "Epoch 245/350\n",
      "47/47 [==============================] - 5s 117ms/step - loss: 7.7937 - val_loss: 9.8484\n",
      "Epoch 246/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 4.2969 - val_loss: 3.5027\n",
      "Epoch 247/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 8.6152 - val_loss: 8.3472\n",
      "Epoch 248/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 4.3370 - val_loss: 10.2018\n",
      "Epoch 249/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 4.2731 - val_loss: 2.3988\n",
      "Epoch 250/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 4.8263 - val_loss: 5.4166\n",
      "Epoch 251/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.2017 - val_loss: 12.1844\n",
      "Epoch 252/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 5.5491 - val_loss: 5.5168\n",
      "Epoch 253/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 2.7053 - val_loss: 2.9154\n",
      "Epoch 254/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 3.3799 - val_loss: 8.9746\n",
      "Epoch 255/350\n",
      "47/47 [==============================] - 6s 117ms/step - loss: 2.6864 - val_loss: 5.1635\n",
      "Epoch 256/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 2.1970 - val_loss: 7.5314\n",
      "Epoch 257/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 1.9992 - val_loss: 7.6044\n",
      "Epoch 258/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 1.8382 - val_loss: 6.8792\n",
      "Epoch 259/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 1.8308 - val_loss: 9.8535\n",
      "Epoch 260/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 2.0959 - val_loss: 6.9618\n",
      "Epoch 261/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 2.0783 - val_loss: 12.0695\n",
      "Epoch 262/350\n",
      "47/47 [==============================] - 5s 117ms/step - loss: 2.9546 - val_loss: 5.9870\n",
      "Epoch 263/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 2.8943 - val_loss: 11.3172\n",
      "Epoch 264/350\n",
      "47/47 [==============================] - 6s 117ms/step - loss: 2.4034 - val_loss: 6.9048\n",
      "Epoch 265/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 1.8512 - val_loss: 10.6420\n",
      "Epoch 266/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 2.9264 - val_loss: 6.9717\n",
      "Epoch 267/350\n",
      "47/47 [==============================] - 6s 117ms/step - loss: 1.3745 - val_loss: 6.9714\n",
      "Epoch 268/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 1.5268 - val_loss: 7.8754\n",
      "Epoch 269/350\n",
      "47/47 [==============================] - 6s 122ms/step - loss: 1.4855 - val_loss: 7.2484\n",
      "Epoch 270/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 0.9730 - val_loss: 7.8401\n",
      "Epoch 271/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 0.8471 - val_loss: 10.0635\n",
      "Epoch 272/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 1.4415 - val_loss: 7.5792\n",
      "Epoch 273/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 1.2989 - val_loss: 9.8460\n",
      "Epoch 274/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 1.3063 - val_loss: 9.1599\n",
      "Epoch 275/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 0.9587 - val_loss: 9.2334\n",
      "Epoch 276/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 0.8829 - val_loss: 9.2014\n",
      "Epoch 277/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 0.8534 - val_loss: 7.1468\n",
      "Epoch 278/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 1.3198 - val_loss: 9.0657\n",
      "Epoch 279/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 1.9248 - val_loss: 7.5084\n",
      "Epoch 280/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 1.4109 - val_loss: 7.8105\n",
      "Epoch 281/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 1.0928 - val_loss: 10.3147\n",
      "Epoch 282/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 1.6698 - val_loss: 4.1096\n",
      "Epoch 283/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 4.6609 - val_loss: 7.8903\n",
      "Epoch 284/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 2.0889 - val_loss: 13.6564\n",
      "Epoch 285/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 4.7963 - val_loss: 5.5686\n",
      "Epoch 286/350\n",
      "47/47 [==============================] - 5s 115ms/step - loss: 3.6425 - val_loss: 7.2387\n",
      "Epoch 287/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 2.7174 - val_loss: 15.4052\n",
      "Epoch 288/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 7.2699 - val_loss: 11.1614\n",
      "Epoch 289/350\n",
      "47/47 [==============================] - 5s 116ms/step - loss: 3.6840 - val_loss: 2.5748\n",
      "Epoch 290/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 6.9157 - val_loss: 9.8677\n",
      "Epoch 291/350\n",
      "47/47 [==============================] - 6s 117ms/step - loss: 2.2232 - val_loss: 11.0647\n",
      "Epoch 292/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 2.3483 - val_loss: 6.5253\n",
      "Epoch 293/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 1.7590 - val_loss: 9.1222\n",
      "Epoch 294/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 1.6171 - val_loss: 6.1341\n",
      "Epoch 295/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 1.4657 - val_loss: 9.4651\n",
      "Epoch 296/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 1.9735 - val_loss: 6.9274\n",
      "Epoch 297/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 1.1886 - val_loss: 8.4199\n",
      "Epoch 298/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 0.6056 - val_loss: 8.4415\n",
      "Epoch 299/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 0.5849 - val_loss: 8.2608\n",
      "Epoch 300/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 1.1453 - val_loss: 9.4378\n",
      "Epoch 301/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 1.4092 - val_loss: 7.8842\n",
      "Epoch 302/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 2.3509 - val_loss: 13.5386\n",
      "Epoch 303/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 4.1208 - val_loss: 5.4031\n",
      "Epoch 304/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 4.4128 - val_loss: 6.3350\n",
      "Epoch 305/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 2.9072 - val_loss: 13.9301\n",
      "Epoch 306/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 6.7128 - val_loss: 8.6206\n",
      "Epoch 307/350\n",
      "47/47 [==============================] - 6s 122ms/step - loss: 3.4914 - val_loss: 2.5498\n",
      "Epoch 308/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 8.1557 - val_loss: 8.9369\n",
      "Epoch 309/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 2.3629 - val_loss: 11.2209\n",
      "Epoch 310/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 2.6379 - val_loss: 5.4965\n",
      "Epoch 311/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 2.2132 - val_loss: 11.7615\n",
      "Epoch 312/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 4.2278 - val_loss: 10.5376\n",
      "Epoch 313/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 2.9951 - val_loss: 3.9429\n",
      "Epoch 314/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 3.1010 - val_loss: 10.8142\n",
      "Epoch 315/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.0295 - val_loss: 8.4563\n",
      "Epoch 316/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 1.4037 - val_loss: 6.4045\n",
      "Epoch 317/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 2.0009 - val_loss: 10.7666\n",
      "Epoch 318/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 2.1781 - val_loss: 5.6353\n",
      "Epoch 319/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 2.2876 - val_loss: 9.9715\n",
      "Epoch 320/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 2.5375 - val_loss: 7.7048\n",
      "Epoch 321/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 1.4642 - val_loss: 5.9053\n",
      "Epoch 322/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 2.2369 - val_loss: 10.6867\n",
      "Epoch 323/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 2.1789 - val_loss: 6.0058\n",
      "Epoch 324/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 2.1468 - val_loss: 10.9477\n",
      "Epoch 325/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 2.7135 - val_loss: 8.7209\n",
      "Epoch 326/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 1.5546 - val_loss: 5.8748\n",
      "Epoch 327/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 2.5061 - val_loss: 10.1692\n",
      "Epoch 328/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 1.6096 - val_loss: 8.1857\n",
      "Epoch 329/350\n",
      "47/47 [==============================] - 5s 116ms/step - loss: 1.2923 - val_loss: 11.3872\n",
      "Epoch 330/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 1.7967 - val_loss: 7.8110\n",
      "Epoch 331/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 1.5717 - val_loss: 10.7924\n",
      "Epoch 332/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 1.4080 - val_loss: 8.0446\n",
      "Epoch 333/350\n",
      "47/47 [==============================] - 5s 117ms/step - loss: 1.1966 - val_loss: 8.5449\n",
      "Epoch 334/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 0.6819 - val_loss: 8.8235\n",
      "Epoch 335/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 0.8883 - val_loss: 9.1163\n",
      "Epoch 336/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 0.8636 - val_loss: 8.5897\n",
      "Epoch 337/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 0.5526 - val_loss: 8.0984\n",
      "Epoch 338/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 1.0005 - val_loss: 9.5318\n",
      "Epoch 339/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 1.6663 - val_loss: 5.6785\n",
      "Epoch 340/350\n",
      "47/47 [==============================] - 5s 116ms/step - loss: 2.6167 - val_loss: 10.6471\n",
      "Epoch 341/350\n",
      "47/47 [==============================] - 6s 121ms/step - loss: 1.5507 - val_loss: 6.7034\n",
      "Epoch 342/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 1.8756 - val_loss: 12.3874\n",
      "Epoch 343/350\n",
      "47/47 [==============================] - 6s 118ms/step - loss: 4.1264 - val_loss: 11.4777\n",
      "Epoch 344/350\n",
      "47/47 [==============================] - 5s 116ms/step - loss: 2.5034 - val_loss: 5.6548\n",
      "Epoch 345/350\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 2.4203 - val_loss: 11.7322\n",
      "Epoch 346/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.7326 - val_loss: 9.9679\n",
      "Epoch 347/350\n",
      "47/47 [==============================] - 6s 117ms/step - loss: 2.5350 - val_loss: 3.4636\n",
      "Epoch 348/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 4.3118 - val_loss: 10.6744\n",
      "Epoch 349/350\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 3.7402 - val_loss: 11.0414\n",
      "Epoch 350/350\n",
      "47/47 [==============================] - 5s 117ms/step - loss: 2.8646 - val_loss: 4.8870\n"
     ]
    }
   ],
   "source": [
    "# Now training the model:\n",
    "N_EPOCHS = 350\n",
    "#BATCH_SIZE = 3000\n",
    "\n",
    "# Fit:\n",
    "history = model.fit(x=X, y=y, \n",
    "          epochs=N_EPOCHS, verbose=1, validation_split=0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_weights_v3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_architecture_v3.json', 'w') as f:\n",
    "    f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['validation', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53.27923]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.88"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6970453560352325"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs((y_test - y_pred) / y_test)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% bias: 2.6970453560352325"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3305795], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * (sum(abs(y_test-y_pred)/(abs(y_test)+abs(y_pred))))/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMAPE: 1.3305795"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3992282104492162"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "sqrt(mean_squared_error(np.array([y_test]), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error: 1.3992282104492162"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
